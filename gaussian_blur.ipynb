{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSTGS8v8KWB/BoH6BVDKI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmanid/image-detexxxtion/blob/main/gaussian_blur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfAtSp88li9k",
        "outputId": "9a6caeaf-2020-4e16-a5ba-93a3710a243b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.2.*\n",
            "  Downloading scipy-1.2.3.tar.gz (23.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scipy\n",
            "  Building wheel for scipy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scipy: filename=scipy-1.2.3-cp38-cp38-linux_x86_64.whl size=42810415 sha256=a6e1ab876130f9c8385bb469ec969949edbf26ff524cf46857a1eda52895d1e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f4/2a/2a6af3129d6d3f1fea59d476fd84326629e4075a73f5f35b1b\n",
            "Successfully built scipy\n",
            "Installing collected packages: scipy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.4.0 requires scipy>=1.6, but you have scipy 1.2.3 which is incompatible.\n",
            "pymc 4.1.4 requires scipy>=1.4.1, but you have scipy 1.2.3 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.2.3 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.2.3 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.2.3 which is incompatible.\n",
            "aeppl 0.0.33 requires scipy>=1.4.0, but you have scipy 1.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.7.3\n"
          ]
        }
      ],
      "source": [
        "# See https://github.com/raghakot/keras-vis/issues/182\n",
        "!pip install -I scipy==1.2.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repositopry to get the MobileNet V1 model by DmitryM8\n",
        "!git clone https://github.com/AIWintermuteAI/transfer_learning_sipeed.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LXaAbnmnJr4",
        "outputId": "6cc90da9-1d8c-46fc-ccc1-d57b194c8409"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transfer_learning_sipeed'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 66 (delta 0), reused 0 (delta 0), pack-reused 63\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout,Flatten\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import sys\n",
        "sys.path.append('/content/transfer_learning_sipeed')\n",
        "from mobilenet_sipeed.mobilenet import MobileNet"
      ],
      "metadata": {
        "id": "YAcD4KZjnMv1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset URL\n",
        "\n",
        "dataset_url = 'https://www.dropbox.com/s/8k8x51cqeyql673/dataset_name.zip?dl=1' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "TAQ006olnPSv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root_dir = '/content/datasets'\n",
        "dataset_tmp_filename = 'dataset.zip'\n",
        "\n",
        "import os\n",
        "\n",
        "# Make the directory for datasets if needed\n",
        "if not os.path.isdir(dataset_root_dir):\n",
        "  os.mkdir(dataset_root_dir)\n",
        "\n",
        "# Download the dataset file from the URL as dataset.zip\n",
        "get_ipython().system_raw('wget -O {} {}'.format(dataset_tmp_filename, dataset_url))"
      ],
      "metadata": {
        "id": "M7A2hlgenSOe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "dataset_name = ''\n",
        "\n",
        "with zipfile.ZipFile(dataset_tmp_filename) as zipfile:\n",
        "    # Get the name of the root directory as the name of the dataset\n",
        "    dataset_name = os.path.dirname(zipfile.namelist()[0]).split(os.sep)[0]\n",
        "    zipfile.extractall(dataset_root_dir)\n",
        "\n",
        "dataset_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b1McB88onU1e",
        "outputId": "5efe065c-ec33-44eb-d9a8-aa87fdf0bba1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset_name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the dataset file\n",
        "if os.path.isfile(dataset_tmp_filename):\n",
        "  os.remove(dataset_tmp_filename)"
      ],
      "metadata": {
        "id": "N9bx3BNJnWaM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "ALPHA = 0.75\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "xyIwxtL9ncBV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "metadata": {
        "id": "xpMhcL_QqnaE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = os.path.join(dataset_root_dir, dataset_name)\n",
        "\n",
        "# Uncomment parameters to enable data augmentation\n",
        "train_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                    # rotation_range=10,\n",
        "                                    # width_shift_range=0.2,\n",
        "                                    # height_shift_range=0.2,\n",
        "                                    # shear_range=0.2,\n",
        "                                    # zoom_range=0.3,\n",
        "                                    # horizontal_flip=True,\n",
        "                                    validation_split=0.1)\n",
        "\n",
        "train_data = train_data_gen.flow_from_directory(dataset_dir,\n",
        "                                                subset='training',\n",
        "                                                target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                color_mode='rgb',\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                class_mode='categorical',\n",
        "                                                shuffle=True)\n",
        "\n",
        "validation_data = train_data_gen.flow_from_directory(dataset_dir,\n",
        "                                                     subset='validation',\n",
        "                                                     target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdBcBz1Wqo7r",
        "outputId": "a475f113-c8f7-4bc2-9110-665e1d2d6c7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32 images belonging to 3 classes.\n",
            "Found 3 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_indices.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvpt6hkbqs8e",
        "outputId": "c7c85afa-bc19-4f05-d6ed-7ab2cdbd59fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('label_1', 0), ('label_2', 1), ('label_3', 2)])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write labels as labels.txt\n",
        "with open('labels.txt', 'wt') as f:\n",
        "    for key, value in train_data.class_indices.items():\n",
        "        f.write(key + '\\n')"
      ],
      "metadata": {
        "id": "zNh_UkcBqwv4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "J5oc2DTvO4wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bad1cd-c378-4811-ca7f-67f6a8fae2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_7_5_224_tf_no_top.h5\n",
            "10626956/10626956 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Using MobileNet V1\n",
        "# See https://keras.io/applications/#mobilenet for details\n",
        "base_model = MobileNet(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "                       alpha=ALPHA,\n",
        "                       include_top=False,\n",
        "                       backend=keras.backend,\n",
        "                       layers=keras.layers,\n",
        "                       models=keras.models,\n",
        "                       utils=keras.utils)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mqcVlH9_0TjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d62308-95c8-4672-81b8-67a34c6b80da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory already exist, images will be written in asme folder\n",
            "Creating_an_Image_Classification_Model_for_M5StickV_by_Transfer_Learning.ipynb.txt is not converted\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import cv2\n",
        "from os import listdir,makedirs\n",
        "from os.path import isfile,join\n",
        "\n",
        "\n",
        "path = r'/content/datasets/dataset_name/label_1' # Source Folder\n",
        "dstpath = r'/content/desfolder1' # Destination Folder\n",
        "\n",
        "try:\n",
        "    makedirs(dstpath)\n",
        "except:\n",
        "    print (\"Directory already exist, images will be written in asme folder\")\n",
        "\n",
        "# Folder won't used\n",
        "files = [f for f in listdir(path) if isfile(join(path,f))] \n",
        "\n",
        "for image in files:\n",
        "    try:\n",
        "        img = cv2.imread(os.path.join(path,image))\n",
        "        gray = cv.GaussianBlur(img,(5,5),0)\n",
        "        dstPath = join(dstpath,image)\n",
        "        cv2.imwrite(dstPath,gray)\n",
        "    except:\n",
        "        print (\"{} is not converted\".format(image))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97wzSy96u8q4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}